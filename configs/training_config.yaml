# Training configuration for crisis-agent fine-tuning
# Optimized for: 16GB VRAM, 4 CPU cores, 32GB RAM
# Adjust these parameters based on your GPU memory and dataset size

training:
  # Output directories
  output_dir: "outputs/checkpoints"
  logging_dir: "outputs/logs"
  final_model_name: "final"  # Name for the final checkpoint directory (e.g., "final", "crisis_agent_v1", "model_2026-01-25")
  
  # Training parameters
  num_epochs: 3
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 4
  learning_rate: 2.0e-4
  warmup_steps: 100
  max_steps: -1  # -1 means use num_epochs instead
  
  # Optimization
  optim: "adamw_torch"
  weight_decay: 0.01
  max_grad_norm: 1.0
  
  # Learning rate schedule
  lr_scheduler_type: "cosine"
  
  # Checkpointing
  save_steps: 500
  save_total_limit: 3
  save_strategy: "steps"
  
  # Evaluation
  eval_steps: 500
  eval_strategy: "steps"
  
  # Logging
  logging_steps: 10
  report_to: []  # Set to ["wandb"] if using Weights & Biases
  
  # Other
  fp16: true
  bf16: false
  dataloader_num_workers: 4  # Matches 4 CPU cores
  remove_unused_columns: false
  seed: 42
  
  # Memory optimization (for 16GB VRAM)
  # If you encounter OOM errors, try:
  # - Reduce per_device_train_batch_size to 1
  # - Increase gradient_accumulation_steps to 8
  # - Reduce max_seq_length in model_config.yaml to 1024
